<h2 id="clip-shorts-title" style="margin-top:0;">Clip‑to‑Shorts Repackager</h2>

<form aria-describedby="clip-shorts-desc">
  <p id="clip-shorts-desc" class="small">
    Upload a gameplay clip, pick a segment, and export a perfectly framed vertical short (9:16) or other preset. Adds caption safe zone and optional watermark.
  </p>

  <div class="row" style="display:grid;grid-template-columns:1fr 1fr;gap:10px;">
    <div class="field">
      <label for="clip-file">Video File</label>
      <input id="clip-file" type="file" accept="video/*" style="width:100%;" />
    </div>

    <div class="field">
      <label for="clip-aspect">Output Aspect</label>
      <select id="clip-aspect" style="width:100%;">
        <option value="9:16">Shorts / TikTok / Reels (9:16)</option>
        <option value="1:1">Instagram Post (1:1)</option>
        <option value="16:9">YouTube (16:9)</option>
      </select>
    </div>

    <div class="field">
      <label for="clip-start">Start Time (seconds)</label>
      <input id="clip-start" type="number" min="0" step="0.1" placeholder="e.g. 12.5" style="width:100%;" />
    </div>

    <div class="field">
      <label for="clip-end">End Time (seconds)</label>
      <input id="clip-end" type="number" min="0" step="0.1" placeholder="e.g. 42.0" style="width:100%;" />
    </div>

    <div class="field">
      <label for="clip-caption">Caption Text (optional)</label>
      <input id="clip-caption" type="text" placeholder="Short caption to overlay" style="width:100%;" />
    </div>

    <div class="field">
      <label for="clip-watermark">Watermark (optional)</label>
      <input id="clip-watermark" type="file" accept="image/*" style="width:100%;" />
    </div>

    <div class="field">
      <label for="clip-scale">Fit Mode</label>
      <select id="clip-scale" style="width:100%;">
        <option value="cover">Cover (crop to fill)</option>
        <option value="contain">Contain (letterbox)</option>
      </select>
    </div>
  </div>

  <div class="actions" style="margin-top:12px;">
    <button type="button" onclick="shortsGenerate(this)">Generate Clip</button>
    <button type="button" class="secondary" onclick="shortsReset(this)">Reset</button>
  </div>
</form>

<div class="results" aria-live="polite" style="margin-top:12px;">
  <h3 class="small">Output & Preview</h3>
  <video id="clip-preview" controls style="max-width:100%;border:1px solid rgba(255,255,255,0.08);display:block;margin-bottom:8px;"></video>
  <div id="clip-actions" style="display:flex;gap:8px;flex-wrap:wrap;">
    <a id="clip-download" class="small" style="display:none;padding:8px 12px;background:#0b84ff;color:#fff;border-radius:6px;text-decoration:none;">Download Clip</a>
    <button id="clip-stop" type="button" style="display:none;" onclick="stopRecording()">Stop</button>
  </div>
  <div id="clip-hint" class="small" style="margin-top:8px;opacity:0.9;"></div>
</div>

<script>
/* Clip‑to‑Shorts Repackager
   - Uses HTML5 video + canvas + MediaRecorder to produce a short clip client-side.
   - Works best for short segments; large files or long segments may be slow or memory heavy.
*/

let _recorder = null;
let _recordedBlobs = null;
let _mediaStream = null;
let _recordingInProgress = false;

function shortsReset(btn){
  const card = btn.closest('.card') || document;
  card.querySelector('form').reset();
  const preview = card.querySelector('#clip-preview');
  preview.src = "";
  preview.style.display = "none";
  card.querySelector('#clip-download').style.display = "none";
  card.querySelector('#clip-hint').textContent = "";
  stopRecording();
}

function parseAspect(aspect){
  const [w,h] = aspect.split(':').map(Number);
  return {w,h};
}

async function shortsGenerate(btn){
  const card = btn.closest('.card') || document;
  const file = card.querySelector('#clip-file').files[0];
  if(!file){
    card.querySelector('#clip-hint').textContent = "Please upload a video file.";
    return;
  }

  // Load video element for source
  const srcURL = URL.createObjectURL(file);
  const srcVideo = document.createElement('video');
  srcVideo.muted = true;
  srcVideo.playsInline = true;
  srcVideo.src = srcURL;

  await srcVideo.play().catch(()=>{}); // allow metadata to load
  await new Promise(resolve => {
    if(srcVideo.readyState >= 2) return resolve();
    srcVideo.onloadedmetadata = () => resolve();
  });

  const start = parseFloat(card.querySelector('#clip-start').value) || 0;
  const end = parseFloat(card.querySelector('#clip-end').value) || Math.min(srcVideo.duration, start + 15);
  if(end <= start){
    card.querySelector('#clip-hint').textContent = "End time must be greater than start time.";
    URL.revokeObjectURL(srcURL);
    return;
  }
  const duration = Math.min(end - start, 60); // cap to 60s for client-side reliability

  const aspect = parseAspect(card.querySelector('#clip-aspect').value);
  // Choose output resolution (use common short resolution while preserving aspect)
  const baseShortHeight = 1920; // for 9:16
  let outW = Math.round(baseShortHeight * (aspect.w / aspect.h));
  let outH = baseShortHeight;
  if(aspect.w / aspect.h >= 1){ // landscape or square
    outW = 1280;
    outH = Math.round(outW * (aspect.h / aspect.w));
  }

  const fitMode = card.querySelector('#clip-scale').value; // cover or contain
  const caption = card.querySelector('#clip-caption').value.trim();
  const watermarkFile = card.querySelector('#clip-watermark').files[0];

  // Prepare canvas
  const canvas = document.createElement('canvas');
  canvas.width = outW;
  canvas.height = outH;
  const ctx = canvas.getContext('2d');

  // Prepare source video playback for drawing frames
  srcVideo.currentTime = start;

  // If browser supports captureStream on video, we can play and draw frames; otherwise use timeupdate loop
  const fps = 30;
  const frameInterval = 1000 / fps;
  let t = 0;
  let stopped = false;

  // Preload watermark image if provided
  let watermarkImg = null;
  if(watermarkFile){
    watermarkImg = await new Promise(resolve=>{
      const r = new FileReader();
      r.onload = e => {
        const img = new Image();
        img.onload = ()=>resolve(img);
        img.src = e.target.result;
      };
      r.readAsDataURL(watermarkFile);
    });
  }

  // Create MediaRecorder from canvas stream
  _mediaStream = canvas.captureStream(fps);
  _recordedBlobs = [];
  try {
    _recorder = new MediaRecorder(_mediaStream, {mimeType: 'video/webm;codecs=vp9'});
  } catch(e){
    try { _recorder = new MediaRecorder(_mediaStream, {mimeType: 'video/webm;codecs=vp8'}); }
    catch(e2){ _recorder = new MediaRecorder(_mediaStream); }
  }

  _recorder.ondataavailable = event => {
    if(event.data && event.data.size) _recordedBlobs.push(event.data);
  };
  _recorder.onstop = () => {
    const superBuffer = new Blob(_recordedBlobs, {type: 'video/webm'});
    const preview = card.querySelector('#clip-preview');
    preview.src = URL.createObjectURL(superBuffer);
    preview.style.display = "block";
    const dl = card.querySelector('#clip-download');
    dl.href = preview.src;
    dl.download = `short-${Math.round(Date.now()/1000)}.webm`;
    dl.style.display = "inline-block";
    card.querySelector('#clip-hint').textContent = `Generated ${Math.round(duration)}s clip. Preview below and use Download to save.`;
    // cleanup
    URL.revokeObjectURL(srcURL);
    _recordingInProgress = false;
  };

  // Start recording
  _recordedBlobs = [];
  _recorder.start(250);
  _recordingInProgress = true;
  card.querySelector('#clip-hint').textContent = "Recording... please wait.";
  card.querySelector('#clip-stop').style.display = "inline-block";

  // Draw loop
  const drawFrame = () => {
    if(stopped) return;
    // Calculate source draw rectangle based on fit mode
    const sw = srcVideo.videoWidth;
    const sh = srcVideo.videoHeight;
    const dw = canvas.width;
    const dh = canvas.height;

    // Determine scale and offsets
    let sx=0, sy=0, sWidth=sw, sHeight=sh;
    const srcRatio = sw/sh;
    const dstRatio = dw/dh;

    if(fitMode === 'cover'){
      if(srcRatio > dstRatio){
        // source wider -> crop sides
        sHeight = sh;
        sWidth = Math.round(sh * dstRatio);
        sx = Math.round((sw - sWidth)/2);
      } else {
        // source taller -> crop top/bottom
        sWidth = sw;
        sHeight = Math.round(sw / dstRatio);
        sy = Math.round((sh - sHeight)/2);
      }
    } else { // contain
      // draw with letterbox
      const scale = Math.min(sw/dw, sh/dh);
      sWidth = Math.round(dw * scale);
      sHeight = Math.round(dh * scale);
      sx = Math.round((sw - sWidth)/2);
      sy = Math.round((sh - sHeight)/2);
    }

    // Clear and draw background (black)
    ctx.fillStyle = "#000";
    ctx.fillRect(0,0,dw,dh);

    // Draw video frame
    try {
      ctx.drawImage(srcVideo, sx, sy, sWidth, sHeight, 0, 0, dw, dh);
    } catch(e){
      // drawing may fail if video not ready; ignore and continue
    }

    // Caption safe zone overlay (bottom)
    if(caption){
      const pad = Math.round(dw * 0.06);
      const panelH = Math.round(dh * 0.18);
      const panelY = dh - panelH - pad;
      ctx.fillStyle = "rgba(0,0,0,0.55)";
      ctx.fillRect(pad, panelY, dw - pad*2, panelH);
      // caption text
      ctx.fillStyle = "#fff";
      ctx.textBaseline = "middle";
      const maxWidth = dw - pad*2 - 20;
      // auto-fit font
      let fontSize = Math.round(panelH * 0.35);
      ctx.font = `bold ${fontSize}px sans-serif`;
      while(ctx.measureText(caption).width > maxWidth && fontSize > 14){
        fontSize -= 2;
        ctx.font = `bold ${fontSize}px sans-serif`;
      }
      ctx.fillText(caption, pad + 10, panelY + panelH/2);
    }

    // Watermark (top-right)
    if(watermarkImg){
      const lw = Math.round(dw * 0.18);
      const lh = Math.round(watermarkImg.height * (lw / watermarkImg.width));
      const mx = dw - lw - 20;
      const my = 20;
      ctx.globalAlpha = 0.95;
      ctx.drawImage(watermarkImg, mx, my, lw, lh);
      ctx.globalAlpha = 1;
    }

    // Safe grid faint border for preview (optional)
    // ctx.strokeStyle = "rgba(255,255,255,0.06)";
    // ctx.strokeRect(Math.round(dw*0.03), Math.round(dh*0.03), Math.round(dw*0.94), Math.round(dh*0.94));

    // Advance source video time
    const current = start + t;
    srcVideo.currentTime = Math.min(current, end);
    t += 1/fps;
    if(start + t >= end || t >= duration){
      // stop
      stopped = true;
      // give recorder a moment to flush frames
      setTimeout(()=>{ try{ _recorder.stop(); } catch(e){} }, 300);
      return;
    }
    // schedule next frame
    setTimeout(drawFrame, frameInterval);
  };

  // Kick off drawing once video is seeked to start
  srcVideo.onseeked = () => {
    // small delay to ensure frame available
    setTimeout(drawFrame, 50);
  };
  // Seek to start to trigger onseeked
  try { srcVideo.currentTime = start; } catch(e){ /* some browsers restrict immediate seek */ setTimeout(()=>srcVideo.currentTime = start, 200); }
}

// Stop recording early (if user clicks stop)
function stopRecording(){
  if(_recorder && _recordingInProgress){
    try{ _recorder.stop(); } catch(e){}
    _recordingInProgress = false;
  }
  if(_mediaStream){
    _mediaStream.getTracks().forEach(t=>t.stop());
    _mediaStream = null;
  }
  _recordingInProgress = false;
  const stopBtn = document.getElementById('clip-stop');
  if(stopBtn) stopBtn.style.display = "none";
}
</script>
